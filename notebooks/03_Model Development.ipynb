{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Développement des modèles de recommandation\n",
    "\n",
    "Ce notebook implémente deux approches principales :\n",
    "\n",
    "1. **Collaborative Filtering (CF)** via Alternating Least Squares (ALS) pondéré par BM25.\n",
    "2. **Content-Based Filtering (CB)** à base de TF-IDF sur les métadonnées des vidéos.\n",
    "\n",
    "Chaque modèle est encapsulé dans une classe Python, facilitant l'entraînement (`fit`) et la génération de recommandations (`recommend`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et définitions de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enroot/epita/s8/reco_sys/FinalProject_2025_lucas.collemare/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from typing import Any, Dict, List, Optional\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Classe `CFModel`\n",
    "Cette classe wrappe un modèle ALS de la librairie `implicit` :\n",
    "- **Paramètres** : nombre de facteurs latents, régularisation, itérations, poids global (`alpha`), et hyperparamètres BM25 (`K1`, `B`).\n",
    "- **`fit`** :\n",
    "  1. Transpose la matrice user–item en item–user.\n",
    "  2. Applique un poids BM25 pour atténuer l'effet des items très fréquents.\n",
    "  3. Entraîne l’ALS.\n",
    "- **`recommend`** :\n",
    "  1. Traduit l’`user_id` en index via `user_map`.\n",
    "  2. Extrait les `N` recommandations non vues.\n",
    "  3. Retourne la liste des `video_id` correspondants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel:\n",
    "    def __init__(self, factors: int = 128, regularization: float = 0.01, iterations: int = 40, alpha: float = 40.0, K1: float = 100, B: float = 0.8):\n",
    "        # Initialisation des hyperparamètres\n",
    "        self.factors = factors\n",
    "        self.reg = regularization\n",
    "        self.iter = iterations\n",
    "        self.alpha = alpha\n",
    "        self.K1 = K1\n",
    "        self.B = B\n",
    "        # Modèle ALS de la librairie implicit\n",
    "        self.model = AlternatingLeastSquares(factors=self.factors, regularization=self.reg, iterations=self.iter)\n",
    "        self.user_items: Optional[sp.csr_matrix] = None\n",
    "\n",
    "    def fit(self, interaction_matrix: sp.csr_matrix):\n",
    "        # Mémorisation de la matrice user–item (csr)\n",
    "        self.user_items = interaction_matrix.tocsr()\n",
    "        # Construction de la matrice item–user\n",
    "        item_user = self.user_items.T\n",
    "        # Pondération BM25\n",
    "        weighted = bm25_weight(item_user, K1=self.K1, B=self.B)\n",
    "        # Entraînement ALS\n",
    "        self.model.fit(weighted)\n",
    "\n",
    "    def recommend(self, user_id: Any, user_map: Dict[Any, int], video_map: Dict[Any, int], interaction_matrix: Optional[sp.csr_matrix] = None, N: int = 10) -> List[Any]:\n",
    "        # Conversion user_id → index\n",
    "        uidx = user_map.get(user_id)\n",
    "        if uidx is None:\n",
    "            return []\n",
    "        # Choix de la matrice d'interaction (passée ou stockée)\n",
    "        if interaction_matrix is not None:\n",
    "            user_items = interaction_matrix.tocsr()\n",
    "        elif self.user_items is not None:\n",
    "            user_items = self.user_items\n",
    "        else:\n",
    "            return []\n",
    "        # Recommandation ALS\n",
    "        ids, scores = self.model.recommend(uidx, user_items, N=N, filter_already_liked_items=True)\n",
    "        # Inversion du mapping pour retrouver les video_id\n",
    "        inv_video_map = {v: k for k, v in video_map.items()}\n",
    "        return [inv_video_map[i] for i in ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Classe `ContentModel`\n",
    "Ce modèle crée un profil TF-IDF pour chaque vidéo puis en déduit un profil utilisateur :\n",
    "- TF-IDF sur le champ `feat` (liste de tokens) des métadonnées.\n",
    "- Alignement des vecteurs TF-IDF sur l’ordre du `video_map`.\n",
    "- Profil utilisateur = produit normalisé matrice d’interaction × TF-IDF.\n",
    "- **`recommend`** : similarité cosinus entre profil utilisateur et TF-IDF vidéos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentModel:\n",
    "    def __init__(self, max_features: int = 10000, ngram_range=(1, 2), stop_words=\"english\"):\n",
    "        # Hyperparamètres TF-IDF\n",
    "        self.max_features = max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.stop_words = stop_words\n",
    "        self.tfidf = TfidfVectorizer( max_features=self.max_features, ngram_range=self.ngram_range, stop_words=self.stop_words)\n",
    "        self.video_ids = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.user_profiles = None\n",
    "        self.user_map = None\n",
    "        self.vid_map = None\n",
    "\n",
    "    def fit(self, metadata_df: pd.DataFrame, interaction_matrix: sp.csr_matrix, user_map: dict, video_map: dict, text_field: str = \"feat\"):\n",
    "        # Conversion des listes en texte brut\n",
    "        def to_text(x):\n",
    "            if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                return \" \".join(str(tok) for tok in x)\n",
    "            if pd.isna(x):\n",
    "                return \"\"\n",
    "            return str(x)\n",
    "        # Construction du corpus\n",
    "        corpus = metadata_df[text_field].apply(to_text).tolist()\n",
    "        tfidf_full = self.tfidf.fit_transform(corpus)\n",
    "        # Alignement de l'ordre des vidéos\n",
    "        all_video_ids = metadata_df[\"video_id\"].tolist()\n",
    "        ordered_videos = [None] * len(video_map)\n",
    "        for vid, idx in video_map.items():\n",
    "            ordered_videos[idx] = vid\n",
    "        id2row = {v: i for i, v in enumerate(all_video_ids)}\n",
    "        rows = [id2row[vid] for vid in ordered_videos]\n",
    "        self.tfidf_matrix = tfidf_full[rows, :]\n",
    "        self.video_ids = ordered_videos\n",
    "        # Normalisation des interactions par utilisateur\n",
    "        um = interaction_matrix.astype(\"float32\")\n",
    "        row_sums = np.array(um.sum(axis=1)).flatten() + 1e-9\n",
    "        um = um.multiply(1.0 / row_sums[:, None])\n",
    "        # Profils utilisateurs = interaction × TF-IDF\n",
    "        self.user_profiles = um.dot(self.tfidf_matrix).toarray()\n",
    "        \n",
    "\t\t# Sauvegarde des artefacts\n",
    "        sparse.save_npz(\"models/tfidf_matrix.npz\", self.tfidf_matrix)\n",
    "        joblib.dump(self.tfidf, \"models/tfidf_vectorizer.pkl\")\n",
    "        joblib.dump(self.user_profiles, \"models/user_profiles.npy\")\n",
    "        joblib.dump(user_map, \"models/user_map_content.pkl\")\n",
    "        joblib.dump(video_map, \"models/video_map_content.pkl\")\n",
    "        self.user_map = user_map\n",
    "        self.vid_map = video_map\n",
    "        print(\"ContentModel: models and profiles saved under models/\")\n",
    "\n",
    "    def recommend(self, user_id, N: int = 10) -> list:\n",
    "        # Chargement à la volée si nécessaire\n",
    "        if self.user_profiles is None:\n",
    "            self.tfidf_matrix = sparse.load_npz(\"models/tfidf_matrix.npz\")\n",
    "            self.user_profiles = joblib.load(\"models/user_profiles.npy\")\n",
    "            self.tfidf = joblib.load(\"models/tfidf_vectorizer.pkl\")\n",
    "            self.user_map = joblib.load(\"models/user_map_content.pkl\")\n",
    "            self.vid_map = joblib.load(\"models/video_map_content.pkl\")\n",
    "\n",
    "        inv_vid_map = {v: k for k, v in self.vid_map.items()}\n",
    "        uidx = self.user_map.get(user_id)\n",
    "        if uidx is None:\n",
    "            return []\n",
    "        profile = self.user_profiles[uidx].reshape(1, -1)\n",
    "        sims = cosine_similarity(profile, self.tfidf_matrix).flatten()\n",
    "        best = np.argpartition(-sims, N)[:N]\n",
    "        best = best[np.argsort(-sims[best])]\n",
    "        return [inv_vid_map[i] for i in best]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entraînement et sauvegarde des modèles\n",
    "On charge les features générées précédemment et on entraîne successivement CFModel puis ContentModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enroot/epita/s8/reco_sys/FinalProject_2025_lucas.collemare/venv/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "/home/enroot/epita/s8/reco_sys/FinalProject_2025_lucas.collemare/venv/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.11811494827270508 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [00:14<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF Model saved to models/\n",
      "ContentModel: models and profiles saved under models/\n",
      "Content-Based Model saved to models/\n"
     ]
    }
   ],
   "source": [
    "def load_features():\n",
    "    # Chargement des données et mappings\n",
    "    mat = sp.load_npz(\"features/interaction_matrix.npz\")\n",
    "    user_map = joblib.load(\"features/user_map.pkl\")\n",
    "    video_map = joblib.load(\"features/video_map.pkl\")\n",
    "    metadata = pd.read_parquet(\"preprocessed/item_categories.parquet\")\n",
    "    return mat, user_map, video_map, metadata\n",
    "\n",
    "# Entraînement du Collaborative Filtering (CF)\n",
    "mat, user_map, video_map, metadata = load_features()\n",
    "model = CFModel(factors=64, regularization=0.05, iterations=20, alpha=40.0)\n",
    "model.fit(mat)\n",
    "joblib.dump(model, f\"models/CF_model.pkl\")\n",
    "print(f\"CF Model saved to models/\")\n",
    "\n",
    "# Entraînement du Content-Based (CB)\n",
    "model = ContentModel(3000, (1,2))\n",
    "model.fit(metadata_df=metadata, interaction_matrix=mat, user_map=user_map, video_map=video_map, text_field=\"feat\")\n",
    "joblib.dump(model, f\"models/Content-Based_model.pkl\")\n",
    "print(f\"Content-Based Model saved to models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Résumé\n",
    "\n",
    "- **CFModel** : ALS + BM25 pour capturer les similarités collaboratives.\n",
    "- **ContentModel** : profil TF-IDF pour exploiter les similarités de contenu.\n",
    "- Les deux modèles sont sauvegardés pour l’étape de génération de recommandations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
