{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DÉPENDANCES À ÉXÉCUTER ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enroot/epita/s8/reco_sys/FinalProject_2025_lucas.collemare/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "class CFModel:\n",
    "    def __init__(self, factors: int = 128, regularization: float = 0.01, iterations: int = 40, alpha: float = 40.0, K1: float = 100, B: float = 0.8):\n",
    "        self.factors = factors\n",
    "        self.reg = regularization\n",
    "        self.iter = iterations\n",
    "        self.alpha = alpha\n",
    "        self.K1 = K1\n",
    "        self.B = B\n",
    "        self.model = AlternatingLeastSquares(factors=self.factors, regularization=self.reg, iterations=self.iter)\n",
    "        self.user_items: Optional[sp.csr_matrix] = None\n",
    "\n",
    "    def fit(self, interaction_matrix: sp.csr_matrix):\n",
    "        self.user_items = interaction_matrix.tocsr()\n",
    "        item_user = self.user_items.T\n",
    "        weighted  = bm25_weight(item_user, K1=self.K1, B=self.B)\n",
    "        self.model.fit(weighted)\n",
    "\n",
    "    def recommend(self, user_id: Any, user_map: Dict[Any, int], video_map: Dict[Any, int], interaction_matrix: Optional[sp.csr_matrix] = None,N: int = 10) -> List[Any]:\n",
    "        uidx = user_map.get(user_id)\n",
    "        if uidx is None:\n",
    "            return []\n",
    "        if interaction_matrix is not None:\n",
    "            user_items = interaction_matrix.tocsr()\n",
    "        elif self.user_items is not None:\n",
    "            user_items = self.user_items\n",
    "        else:\n",
    "            return []\n",
    "        ids, scores = self.model.recommend(\n",
    "            uidx,\n",
    "            user_items,\n",
    "            N=N,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "        inv_video_map = {v: k for k, v in video_map.items()}\n",
    "        return [inv_video_map[i] for i in ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.sparse as sp\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "class ContentModel:\n",
    "    def __init__(self, max_features: int = 10000, ngram_range=(1, 2), stop_words=\"english\"):\n",
    "        self.max_features = max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.stop_words = stop_words\n",
    "        self.tfidf = TfidfVectorizer(max_features=self.max_features, ngram_range=self.ngram_range, stop_words=self.stop_words)\n",
    "        self.video_ids = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.user_profiles = None\n",
    "        self.user_map = None\n",
    "        self.vid_map = None\n",
    "\n",
    "    def fit(self, metadata_df: pd.DataFrame, interaction_matrix: sp.csr_matrix, user_map: dict, video_map: dict, text_field: str = \"feat\"):\n",
    "        def to_text(x):\n",
    "            if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                return \" \".join(str(tok) for tok in x)\n",
    "            if pd.isna(x):\n",
    "                return \"\"\n",
    "            return str(x)\n",
    "        corpus = metadata_df[text_field].apply(to_text).tolist()\n",
    "        tfidf_full = self.tfidf.fit_transform(corpus)\n",
    "        all_video_ids = metadata_df[\"video_id\"].tolist()\n",
    "        ordered_videos = [None] * len(video_map)\n",
    "        for vid, idx in video_map.items():\n",
    "            ordered_videos[idx] = vid\n",
    "        id2row = {v: i for i, v in enumerate(all_video_ids)}\n",
    "        rows = [id2row[vid] for vid in ordered_videos]\n",
    "        tfidf_aligned = tfidf_full[rows, :]\n",
    "        self.tfidf_matrix = tfidf_aligned\n",
    "        self.video_ids = ordered_videos\n",
    "        um = interaction_matrix.astype(\"float32\")\n",
    "        row_sums = np.array(um.sum(axis=1)).flatten() + 1e-9\n",
    "        um = um.multiply(1.0 / row_sums[:, None])\n",
    "        self.user_profiles = um.dot(self.tfidf_matrix).toarray()\n",
    "        sparse.save_npz(\"models/tfidf_matrix.npz\", self.tfidf_matrix)\n",
    "        joblib.dump(self.tfidf, \"models/tfidf_vectorizer.pkl\")\n",
    "        joblib.dump(self.user_profiles, \"models/user_profiles.npy\")\n",
    "        joblib.dump(user_map, \"models/user_map_content.pkl\")\n",
    "        joblib.dump(video_map, \"models/video_map_content.pkl\")\n",
    "        self.user_map = user_map\n",
    "        self.vid_map = video_map\n",
    "        print(\"ContentModel: models and profiles saved under models/\")\n",
    "\n",
    "    def recommend(self, user_id, N: int = 10) -> list:\n",
    "        if self.user_profiles is None:\n",
    "            self.tfidf_matrix = sparse.load_npz(\"models/tfidf_matrix.npz\")\n",
    "            self.user_profiles = joblib.load(\"models/user_profiles.npy\")\n",
    "            self.tfidf = joblib.load(\"models/tfidf_vectorizer.pkl\")\n",
    "            self.user_map = joblib.load(\"models/user_map_content.pkl\")\n",
    "            self.vid_map = joblib.load(\"models/video_map_content.pkl\")\n",
    "        inv_vid_map = {v: k for k, v in self.vid_map.items()}\n",
    "        uidx = self.user_map.get(user_id)\n",
    "        if uidx is None:\n",
    "            return []\n",
    "        profile = self.user_profiles[uidx].reshape(1, -1)\n",
    "        sims = cosine_similarity(profile, self.tfidf_matrix).flatten()\n",
    "        best = np.argpartition(-sims, N)[:N]\n",
    "        best = best[np.argsort(-sims[best])]\n",
    "        return [inv_vid_map[i] for i in best]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Génération des recommandations\n",
    "Ce notebook utilise les modèles entraînés précédemment (CF, Content-Based et Hybrid) pour produire des listes de recommandations sur le jeu de test.\n",
    "\n",
    "**Étapes principales :**\n",
    "1. Chargement des données de test (`small_matrix.csv`).\n",
    "2. Chargement des modèles et des mappings.\n",
    "3. Génération des recommandations pour chaque utilisateur :\n",
    "   - **CF-only** via `CF_model.pkl`\n",
    "   - **Content-only** via `ContentBased_model.pkl`\n",
    "   - **Hybrid + Popularité** (combinaison pondérée CF & CB + fallback populaire)\n",
    "4. Export des résultats au format CSV (`submission_cf.csv`, `submission_content.csv`, `submission_hybrid.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préliminaires : imports et chargements\n",
    "\n",
    "On importe les librairies nécessaires et on charge le jeu de test ainsi que les mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Chargement du jeu de test (liste d'utilisateurs à scorer)\n",
    "test = pd.read_csv(\"../data/small_matrix.csv\")\n",
    "users = test['user_id'].unique()\n",
    "\n",
    "# Chargement des artefacts CF\n",
    "def load_cf_artifacts():\n",
    "    model = joblib.load(\"models/CF_model.pkl\")\n",
    "    user_map = joblib.load(\"features/user_map.pkl\")\n",
    "    video_map = joblib.load(\"features/video_map.pkl\")\n",
    "    interaction_matrix = sp.load_npz(\"features/interaction_matrix.npz\").tocsr()\n",
    "    return model, user_map, video_map, interaction_matrix\n",
    "\n",
    "# Chargement des artefacts CB\n",
    "def load_cb_artifacts():\n",
    "    model = joblib.load(\"models/Content-Based_model.pkl\")\n",
    "    return model\n",
    "\n",
    "# Fallback popular videos\n",
    "\n",
    "def load_popular_list(big_csv=\"../data/big_matrix.csv\"):\n",
    "    \"\"\"\n",
    "    Construit une liste de vidéos triées par popularité (nombre d'interactions).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(big_csv, usecols=[\"video_id\"])\n",
    "    return df[\"video_id\"].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Génération CF-only\n",
    "Pour chaque utilisateur :\n",
    "- Récupérer l'index via `user_map`\n",
    "- Appeler `model.recommend(...)`\n",
    "- Stocker la liste de `video_id`, le rang et le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_cf.csv\n"
     ]
    }
   ],
   "source": [
    "cf_model, cf_user_map, cf_video_map, cf_matrix = load_cf_artifacts()\n",
    "inv_cf_map = {v: k for k, v in cf_video_map.items()}\n",
    "\n",
    "user_items = cf_matrix.tocsr()\n",
    "inv_video_map = {v:k for k,v in cf_video_map.items()}\n",
    "recs = []\n",
    "als = getattr(cf_model, \"model\", cf_model)\n",
    "for u in users:\n",
    "\tuidx = cf_user_map.get(u)\n",
    "\tif uidx is None:\n",
    "\t\tcontinue\n",
    "\tpairs = als.recommend(uidx, user_items, N=10, filter_already_liked_items=False)\n",
    "\tids, scores = pairs\n",
    "\tfor rank, (vidx, score) in enumerate(zip(ids, scores), start=1):\n",
    "\t\trecs.append({\n",
    "\t\t\t'user_id': u,\n",
    "\t\t\t'video_id': inv_video_map[vidx],\n",
    "\t\t\t'rank': rank,\n",
    "\t\t\t'score': score\n",
    "\t\t})\n",
    "pd.DataFrame(recs).to_csv(\"submission_cf.csv\", index=False)\n",
    "print(f\"Submission saved to submission_cf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Génération Content-only\n",
    "\n",
    "Pour chaque utilisateur :\n",
    "- Appeler `cb_model.recommend(user_id, N)`\n",
    "- Stocker les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-only recommendations saved to submission_content.csv\n"
     ]
    }
   ],
   "source": [
    "cb_model = load_cb_artifacts()\n",
    "\n",
    "cb_recs = []\n",
    "for u in users:\n",
    "    recs = cb_model.recommend(u, N=10)\n",
    "    for rank, vid in enumerate(recs, start=1):\n",
    "        cb_recs.append({'user_id': u, 'video_id': vid, 'rank': rank})\n",
    "\n",
    "pd.DataFrame(cb_recs).to_csv(\"submission_content.csv\", index=False)\n",
    "print(\"Content-only recommendations saved to submission_content.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Génération Hybrid + Popularité\n",
    "\n",
    "On combine les scores CF et CB avec un poids `alpha` puis on complète par une liste de fallback basée sur la popularité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid+pop submission saved to submission_hybrid.csv\n"
     ]
    }
   ],
   "source": [
    "cf_model = joblib.load(\"models/CF_model.pkl\")\n",
    "cb_model = joblib.load(\"models/Content-Based_model.pkl\")\n",
    "user_items_cf = cf_model.user_items\n",
    "user_map_cf  = joblib.load(\"features/user_map.pkl\")\n",
    "video_map_cf = joblib.load(\"features/video_map.pkl\")\n",
    "inv_video_map = {col: vid for vid, col in video_map_cf.items()}\n",
    "pop_list = load_popular_list()\n",
    "N     = 10\n",
    "alpha = 0.7\n",
    "CF_K  = (5 * N)\n",
    "CB_K  = (5 * N)\n",
    "item_factors = cf_model.model.user_factors\n",
    "user_factors = cf_model.model.item_factors\n",
    "recs = []\n",
    "for u in users:\n",
    "\tscores = {}\n",
    "\tif u in user_map_cf:\n",
    "\t\tuidx = user_map_cf[u]\n",
    "\t\tuvec = user_factors[uidx]\n",
    "\t\tsc_cf = item_factors.dot(uvec)\n",
    "\t\tseen = user_items_cf[uidx].indices\n",
    "\t\tsc_cf[seen] = -np.inf\n",
    "\t\ttop_cf = np.argpartition(-sc_cf, CF_K)[:CF_K]\n",
    "\t\ttop_cf = top_cf[np.argsort(-sc_cf[top_cf])]\n",
    "\t\tfor idx in top_cf:\n",
    "\t\t\tscores[idx] = scores.get(idx, 0.0) + alpha * sc_cf[idx]\n",
    "\tif u in cb_model.user_map:\n",
    "\t\tuidx_cb = cb_model.user_map[u]\n",
    "\t\tup      = cb_model.user_profiles[uidx_cb].reshape(1, -1)\n",
    "\t\tsc_cb   = cosine_similarity(up, cb_model.tfidf_matrix).flatten()\n",
    "\t\ttop_cb  = np.argpartition(-sc_cb, CB_K)[:CB_K]\n",
    "\t\ttop_cb  = top_cb[np.argsort(-sc_cb[top_cb])]\n",
    "\t\tfor idx in top_cb:\n",
    "\t\t\tscores[idx] = scores.get(idx, 0.0) + (1 - alpha) * sc_cb[idx]\n",
    "\tranked = sorted(scores, key=lambda i: -scores[i])\n",
    "\tvids = [inv_video_map[i] for i in ranked]\n",
    "\tif len(vids) < N:\n",
    "\t\tfor p in pop_list:\n",
    "\t\t\tif p not in vids:\n",
    "\t\t\t\tvids.append(p)\n",
    "\t\t\tif len(vids) == N:\n",
    "\t\t\t\tbreak\n",
    "\tvids = vids[:N]\n",
    "\tfor rank, vid in enumerate(vids, start=1):\n",
    "\t\tscore = scores.get(video_map_cf.get(vid, None), 0.0)\n",
    "\t\trecs.append({\n",
    "\t\t\t\"user_id\":  u,\n",
    "\t\t\t\"video_id\": vid,\n",
    "\t\t\t\"rank\":     rank,\n",
    "\t\t\t\"score\":    float(score)\n",
    "\t\t})\n",
    "pd.DataFrame(recs).to_csv(\"submission_hybrid.csv\", index=False)\n",
    "print(f\"Hybrid+pop submission saved to submission_hybrid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Les fichiers CSV générés (`submission_cf.csv`, `submission_content.csv`, `submission_hybrid.csv`) sont utilisés pour l'évaluation dans 05_Evaluate.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
